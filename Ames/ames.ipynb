{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "26a2e89b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "07d4471a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('AmesHousing.csv')\n",
    "df.columns = df.columns.str.replace(' ', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a13bd302",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              Total    Percent\n",
      "PoolQC         2917  99.556314\n",
      "MiscFeature    2824  96.382253\n",
      "Alley          2732  93.242321\n",
      "Fence          2358  80.477816\n",
      "MasVnrType     1775  60.580205\n",
      "FireplaceQu    1422  48.532423\n",
      "LotFrontage     490  16.723549\n",
      "GarageQual      159   5.426621\n",
      "GarageYrBlt     159   5.426621\n",
      "GarageCond      159   5.426621\n",
      "GarageFinish    159   5.426621\n",
      "GarageType      157   5.358362\n",
      "BsmtExposure     83   2.832765\n",
      "BsmtFinType2     81   2.764505\n",
      "BsmtQual         80   2.730375\n",
      "BsmtCond         80   2.730375\n",
      "BsmtFinType1     80   2.730375\n",
      "MasVnrArea       23   0.784983\n",
      "BsmtFullBath      2   0.068259\n",
      "BsmtHalfBath      2   0.068259\n",
      "TotalBsmtSF       1   0.034130\n",
      "BsmtFinSF1        1   0.034130\n",
      "BsmtFinSF2        1   0.034130\n",
      "GarageArea        1   0.034130\n",
      "GarageCars        1   0.034130\n",
      "BsmtUnfSF         1   0.034130\n",
      "Electrical        1   0.034130\n"
     ]
    }
   ],
   "source": [
    "#This is used to find the percentage of missing values----------------\n",
    "total = df.isnull().sum().sort_values(ascending=False)\n",
    "percent = (df.isnull().sum() / df.isnull().count() * 100).sort_values(ascending=False)\n",
    "missing_data = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\n",
    "missing_data = missing_data[missing_data['Total'] > 0]\n",
    "\n",
    "print(missing_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7d3f9dbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Remaining Missing Values: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\harsh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:1214: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "c:\\Users\\harsh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:1214: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n"
     ]
    }
   ],
   "source": [
    "'''Now, here it's possible that some of the columns have no value, because there's nothing htere genuinly, like 0 means no garage.\n",
    "So we also have to look out for that'''\n",
    "\n",
    "# 1. The \"None\" Class (Categorical features where NaN means \"Not Present\")\n",
    "none_cols = [\n",
    "    'Alley', 'BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1', \n",
    "    'BsmtFinType2', 'FireplaceQu', 'GarageType', 'GarageFinish', \n",
    "    'GarageQual', 'GarageCond', 'PoolQC', 'Fence', 'MiscFeature', \n",
    "    'MasVnrType'\n",
    "]\n",
    "\n",
    "# Fill these with the string \"None\"\n",
    "for col in none_cols:\n",
    "    df[col] = df[col].fillna('None')\n",
    "\n",
    "# 2. The \"Zero\" Class (Numerical features where NaN means 0)\n",
    "zero_cols = [\n",
    "    'GarageYrBlt', 'GarageArea', 'GarageCars', \n",
    "    'BsmtFinSF1', 'BsmtFinSF2', 'BsmtUnfSF',\n",
    "    'TotalBsmtSF', 'BsmtFullBath', 'BsmtHalfBath', \n",
    "    'MasVnrArea'\n",
    "]\n",
    "\n",
    "# Fill these with the number 0\n",
    "for col in zero_cols:\n",
    "    df[col] = df[col].fillna(0)\n",
    "\n",
    "\n",
    "df['LotFrontage'] = df.groupby('Neighborhood')['LotFrontage'].transform(\n",
    "    lambda x: x.fillna(x.median())\n",
    ")\n",
    "\n",
    "# df.mode() returns a dataframe, so we take [0] to get the first value\n",
    "df['Electrical'] = df['Electrical'].fillna(df['Electrical'].mode()[0])\n",
    "\n",
    "# --- VERIFICATION ---\n",
    "# Check if anything is still missing\n",
    "print(\"Remaining Missing Values:\", df.isnull().sum().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ed81bac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Now we check for skewness of sales price, it's skewed 1.7 hence we use log transform'''\n",
    "df['SalePrice'] = np.log1p(df['SalePrice'])\n",
    "\n",
    "'''Also in the dataset we can see that some recrods are like\n",
    " Example: Kitchen Qual has values: Ex (Excellent), Gd (Good), TA (Typical), Fa (Fair), Po (Poor). \n",
    " Hence we can't use normal encoding, we must manually map them to numbers'''\n",
    "\n",
    "quality_map = {\n",
    "    'Ex': 5,  # Excellent\n",
    "    'Gd': 4,  # Good\n",
    "    'TA': 3,  # Typical/Average\n",
    "    'Fa': 2,  # Fair\n",
    "    'Po': 1,  # Poor\n",
    "    'None': 0 # Not Present (We filled this in Phase 1)\n",
    "}\n",
    "\n",
    "# B. List the columns that use this specific scale\n",
    "# (Checked against dataset documentation)\n",
    "ordinal_cols = [\n",
    "    'Exter Qual',   # Exterior material quality\n",
    "    'Exter Cond',   # Exterior material condition\n",
    "    'Bsmt Qual',    # Height of the basement\n",
    "    'Bsmt Cond',    # General condition of the basement\n",
    "    'Heating QC',   # Heating quality and condition\n",
    "    'Kitchen Qual', # Kitchen quality\n",
    "    'Fireplace Qu', # Fireplace quality\n",
    "    'Garage Qual',  # Garage quality\n",
    "    'Garage Cond',  # Garage condition\n",
    "    'Pool QC'       # Pool quality\n",
    "]\n",
    "\n",
    "for col in ordinal_cols:\n",
    "    if col in df.columns:\n",
    "        df[col] = df[col].map(quality_map)\n",
    "        # IMPORTANT: If a value wasn't in our dictionary (like a typo), \n",
    "        # map turns it into NaN. We fill those rare cases with 3 (Average).\n",
    "        df[col] = df[col].fillna(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "349c7c8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Now we deal with the remaining columns\n",
    "WE just apply one hot encoder to this simple AFF'''\n",
    "\n",
    "nominal_cols = df.select_dtypes(include=['object']).columns.tolist()\n",
    "df_encoded = pd.get_dummies(df, columns=nominal_cols, drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a0e392b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Model... (This might take 10-20 seconds)\n",
      "\n",
      "--- RESULTS ---\n",
      "Training RMSE: 0.0532 (Lower is better)\n",
      "Test RMSE:     0.1216 (Target: < 0.14)\n",
      "Test R2 Score: 0.9201\n",
      "\n",
      "--- REALITY CHECK (First House in Test Set) ---\n",
      "Actual Price:    $161,000.00\n",
      "Predicted Price: $166,318.27\n",
      "Error:           $-5,318.27\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "# 1. Prepare Data\n",
    "# df_encoded is our fully numeric dataframe from Phase 3\n",
    "X = df_encoded.drop('SalePrice', axis=1)\n",
    "y = df_encoded['SalePrice'] # Already Log-Transformed in Phase 2\n",
    "\n",
    "# 2. Split (Standard 80/20)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 3. Initialize Model\n",
    "# n_estimators=500: More trees = more stable\n",
    "# n_jobs=-1: Use all CPU cores (faster)\n",
    "model = RandomForestRegressor(n_estimators=500, random_state=42, n_jobs=-1)\n",
    "\n",
    "print(\"Training Model... (This might take 10-20 seconds)\")\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# 4. Evaluate\n",
    "y_pred_train = model.predict(X_train)\n",
    "y_pred_test = model.predict(X_test)\n",
    "\n",
    "# Calculate RMSE (Root Mean Squared Error)\n",
    "# Since y is already log-scale, this IS the \"Log RMSE\"\n",
    "rmse_train = np.sqrt(mean_squared_error(y_train, y_pred_train))\n",
    "rmse_test = np.sqrt(mean_squared_error(y_test, y_pred_test))\n",
    "\n",
    "# Calculate R2 just for reference\n",
    "r2_test = r2_score(y_test, y_pred_test)\n",
    "\n",
    "print(\"\\n--- RESULTS ---\")\n",
    "print(f\"Training RMSE: {rmse_train:.4f} (Lower is better)\")\n",
    "print(f\"Test RMSE:     {rmse_test:.4f} (Target: < 0.14)\")\n",
    "print(f\"Test R2 Score: {r2_test:.4f}\")\n",
    "\n",
    "# 5. Interpretation (Reverse the Logs to see real dollars)\n",
    "# We take a sample prediction to see the dollar error\n",
    "sample_idx = 0\n",
    "real_price = np.expm1(y_test.iloc[sample_idx])\n",
    "pred_price = np.expm1(y_pred_test[sample_idx])\n",
    "error = real_price - pred_price\n",
    "\n",
    "print(\"\\n--- REALITY CHECK (First House in Test Set) ---\")\n",
    "print(f\"Actual Price:    ${real_price:,.2f}\")\n",
    "print(f\"Predicted Price: ${pred_price:,.2f}\")\n",
    "print(f\"Error:           ${error:,.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8fa94ba2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training XGBoost...\n",
      "\n",
      "--- XGBoost RESULTS ---\n",
      "Training RMSE: 0.0296\n",
      "Test RMSE:     0.1012\n",
      "Best Iteration: 684 (It stopped early!)\n",
      "\n",
      "Improvement over Random Forest: 0.0204\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# 1. Initialize the Model\n",
    "# We use a small learning rate (0.05) and many trees (1000) for precision.\n",
    "xg_reg = xgb.XGBRegressor(\n",
    "    objective='reg:squarederror', # We are doing regression, not classification\n",
    "    n_estimators=1000,            # Max number of trees\n",
    "    learning_rate=0.05,           # \"Step size\" - smaller is more accurate but slower\n",
    "    max_depth=5,                  # How deep each tree can grow (prevent overfitting)\n",
    "    early_stopping_rounds=50,     # Stop if validation score stops improving\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "print(\"Training XGBoost...\")\n",
    "\n",
    "# 2. Fit with \"Early Stopping\"\n",
    "# This requires passing the Test set (eval_set) so it knows when to stop.\n",
    "# verbose=False keeps the output clean (otherwise it prints 1000 lines).\n",
    "xg_reg.fit(\n",
    "    X_train, y_train,\n",
    "    eval_set=[(X_test, y_test)],\n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "# 3. Predict & Evaluate\n",
    "y_pred_xgb = xg_reg.predict(X_test)\n",
    "y_train_xgb = xg_reg.predict(X_train)\n",
    "\n",
    "# Calculate RMSE\n",
    "rmse_train_xgb = np.sqrt(mean_squared_error(y_train, y_train_xgb))\n",
    "rmse_test_xgb = np.sqrt(mean_squared_error(y_test, y_pred_xgb))\n",
    "\n",
    "print(\"\\n--- XGBoost RESULTS ---\")\n",
    "print(f\"Training RMSE: {rmse_train_xgb:.4f}\")\n",
    "print(f\"Test RMSE:     {rmse_test_xgb:.4f}\")\n",
    "print(f\"Best Iteration: {xg_reg.best_iteration} (It stopped early!)\")\n",
    "\n",
    "# 4. Compare with Random Forest (Previous Best)\n",
    "# rf_rmse_test was roughly 0.1216\n",
    "improvement = 0.1216 - rmse_test_xgb\n",
    "print(f\"\\nImprovement over Random Forest: {improvement:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
